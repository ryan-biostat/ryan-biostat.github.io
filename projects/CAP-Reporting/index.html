<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CAP Lab Instrument QC Report | Ryan Gallagher </title> <meta name="author" content="Ryan Gallagher"> <meta name="description" content="statistical reporting via RMarkdown for measuring instrument performance"> <meta name="keywords" content="biostatistics, statistical genetics, genomics, genome assembly, bioinformatics, Ryan Gallagher"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A7%AC&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ryan-biostat.github.io/projects/CAP-Reporting/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ryan</span> Gallagher </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="https://github.com/ryan-biostat/ryan-biostat.github.io/tree/main/assets/pdf/RG_CV_11082025.pdf" rel="external nofollow noopener" target="_blank">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/presentations/">presentations </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">CAP Lab Instrument QC Report</h1> <p class="post-description">statistical reporting via RMarkdown for measuring instrument performance</p> </header> <article> <h4 id="about"><strong>About</strong></h4> <p>The Advanced Genomics Lab operates with two complementary missions: a clinical arm focused on patient diagnostics and a research arm dedicated to developing and improving genomic technologies. As a Biostatistician, my primary role is within the research arm, where I build statistical methods for analyzing genomic data and interpreting sequencing results. Secondarily, I get the opportunity to collaborate with the clinical laboratory whenever statistical expertise is needed to support diagnostic workflows.</p> <p>Our lab relies on several high-performance instruments for sequencing, and maintaining CAP accreditation requires routine evaluation of these machines using manufacturer-defined quality control (QC) metrics. This project of developing a statistical reporting framework for QC assessment of our Scanner and Fluidics systems originated as an open-ended request from the clinical team. It became an awesome opportunity to apply statistical methodology in a real laboratory setting and strengthen my skills in report generation and scientific communication.</p> <h2 id="purpose"><strong>Purpose</strong></h2> <p>Clinical laboratories operate under strict regulatory standards to ensure the accuracy, reliability, and safety of diagnostic testing. One of the highest benchmarks in the United States is <a href="https://www.cap.org/laboratory-improvement/accreditation/laboratory-accreditation-program" rel="external nofollow noopener" target="_blank">CAP accreditation</a>, issued by the College of American Pathologists. CAP-accredited labs must demonstrate that their instruments, workflows, and analytical processes consistently meet rigorous quality standards. A key component of this accreditation is the ongoing evaluation of instrument performance using manufacturer-defined quality control (QC) metrics.</p> <p>In our lab, instrument systems directly support sequencing, so the clinical arm depends on equivalent performance across machines. Subtle deviations can signal emerging issues that may affect sample integrity or raise CAP compliance concerns. This project addresses that need by establishing a routine, statistically grounded reporting system that analyzes QC data on a recurring schedule. Statistical methods provide the framework to distinguish true changes from natural variability and quantify uncertainty, while structured report generation translates these findings into summaries for clinical leadership and potential auditors.</p> <h2 id="methods"><strong>Methods</strong></h2> <p>Generate quarterly statistical reports for our CAP lab to evaluate QC metrics.</p> <ol> <li> <h4 id="understand-the-problem"><strong>Understand the Problem</strong></h4> <p>To begin this project, I met with our lab director and clinical staff to develop a clear understanding of the instruments involved and how their quality-control metrics are measured. These discussions helped establish context for my reporting. Our laboratory relies on two Scanners and six Fluidics machines, each contributing critical steps in sample processing. These conversations formed the foundation for the statistical approach by showing how metrics were currently being monitored and what gaps a more formal reporting system needed to address.</p> </li> <li> <h4 id="interpret-the-data"><strong>Interpret the Data</strong></h4> <p>The next step was to ingest the available data and evaluate its structure, completeness, and reliability. I began by importing the raw QC files from each Scanner and Fluidics machine, checking for inconsistencies such as missing fields or unexpected value ranges. During this process I worked directly with the manufacturer to clarify how certain values were calculated and what constituted normal operating variation. At the same time, I collaborated with the clinical team to establish a quarterly plan for data retrieval. This created a reliable pipeline for ongoing reporting and positioned the lab for sustainable long-term monitoring.</p> </li> <li> <h4 id="generate-a-report"><strong>Generate a Report</strong></h4> <p>I developed an automated reporting framework using <a href="https://rmarkdown.rstudio.com/" rel="external nofollow noopener" target="_blank">RMarkdown</a> to integrate statistical analysis, visualization, and written interpretation into a single reproducible document. The report executes a series of statistical tests tailored to each QC metric, evaluates model assumptions analyses, and generating conclusions based on p-values. For the Fluidics systems, I additionally implemented a <a href="https://www.statsmodels.org/stable/mixed_linear.html" rel="external nofollow noopener" target="_blank">mixed-effects model</a> to identify which factors (like machine, run date, or sample batch) exert the strongest influence on QC outcomes. This modeling approach allowed the report to move beyond simple comparisons and toward an understanding of underlying drivers in instrument behavior. The resulting RMarkdown report is robust and produces repeatable summaries that can be regenerated each quarter as new data is generated.</p> </li> <li> <h4 id="communicate-results"><strong>Communicate Results</strong></h4> <p>After completing the analyses, I met with the lab director and clinical staff to walk through the key findings. I presented the workflow from data acquisition through modeling, explained my reasoning behind each analytical step, and highlighted the most relevant outcomes for both each system. My goal was to ensure that the statistical results were understandable, actionable, and aligned with the lab’s operational needs and CAP expectations. These reports continue to be generated and aid in machine evaluation for our lab.</p> </li> </ol> <h2 id="code-sample"><strong>Code Sample</strong></h2> <figure class="highlight"><pre><code class="language-r" data-lang="r"><table class="rouge-table"><tbody><tr>
<td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
</pre></td> <td class="code"><pre><span class="n">title</span><span class="o">:</span><span class="w"> </span><span class="s2">"Scanner Comparison - May 2025 Scanner Comparison"</span><span class="w">
</span><span class="n">author</span><span class="o">:</span><span class="w"> </span><span class="s2">"Ryan Gallagher"</span><span class="w">
</span><span class="n">date</span><span class="o">:</span><span class="w"> </span><span class="s2">"`r Sys.Date()`"</span><span class="w">
</span><span class="n">output</span><span class="o">:</span><span class="w"> </span><span class="n">pdf_document</span><span class="w">
</span><span class="o">---</span><span class="w">

</span><span class="err">``</span><span class="n">`{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(kableExtra)
library(GGally)
library(htmltools)
library(gridExtra)


T1.file = "REDACTED"
T2.file = "REDACTED"

s3 = read.table(T1.file, header=TRUE, sep='\t') %&gt;% mutate(Scanner = "Scanner 1", Batch="632")
s4 = read.table(T2.file, header=TRUE, sep='\t') %&gt;% mutate(Scanner = "Scanner 2", Batch="632")

names(s3)[6] &lt;- "SNPQC.GreaterThanOrEqual.15.00"
names(s4)[6] &lt;- "SNPQC.GreaterThanOrEqual.15.00"

s = rbind(s3, s4)

t1 = s %&gt;% filter(Scanner == "Scanner 1")
t2 = s %&gt;% filter(Scanner == "Scanner 2")
`</span><span class="err">`</span><span class="n">`

### Analysis Description

The objective of this report is to determine whether there is a measurable difference between the scanners Scanner 1 &amp; Scanner 2. Three metrics are provided: `MAPD`, `SNPQC`, `Waviness.SD` as well as identifiers for scanner. This report will summarize these metrics per scanner then runs statistical tests to determine if the groups are significantly different.

The data used in this report are:

-   `REDACTED` for May 15th, 2025

This batch consisted of 11 patient samples and 1 control (`CytoRef103`).

### Summary Statistics

The objective of this section is to describe the data and determine the distribution within each group to then allow us to compare the data across scanners.

For each metric within each group, we summarize the data and test whether they approximately follow a normal distribution using the Shapiro-Wilks Test. Our interpretation is that if the p-value is **less than 0.05 then we reject the null** **that our data is approximately normal**.

`</span><span class="err">`</span><span class="n">`{r all, fig.align = 'center', echo=FALSE}

library(dplyr)
library(knitr)
library(kableExtra)

summary_table.s = s %&gt;%
  group_by(Scanner) %&gt;%
  summarize(
    N = n(),
    MAPD_mean = mean(MAPD, na.rm = TRUE),
    MAPD_sd = sd(MAPD, na.rm = TRUE),
    MAPD_shapiro_p = if (N &gt; 2) shapiro.test(MAPD)$p.value else NA,
    SNPQC_mean = mean(SNPQC, na.rm = TRUE),
    SNPQC_sd = sd(SNPQC, na.rm = TRUE),
    SNPQC_shapiro_p = if (N &gt; 2) shapiro.test(SNPQC)$p.value else NA,
    Waviness_SD_mean = mean(`Waviness.SD`, na.rm = TRUE),
    Waviness_SD_sd = sd(`Waviness.SD`, na.rm = TRUE),
    Waviness_SD_shapiro_p = if (N &gt; 2) shapiro.test(`Waviness.SD`)$p.value else NA
  ) %&gt;%
  ungroup()

summary_table.s %&gt;%
  kable(
    digits = 2,      
    col.names = c("Scanner", "N", 
                  "Mean", "SD", "Shapiro p-value", 
                  "Mean", "SD", "Shapiro p-value", 
                  "Mean", "SD", "Shapiro p-value"),
    caption = "Summary of Metrics by Scanner with Shapiro-Wilk Test Results"
  ) %&gt;%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"), position = "center") %&gt;%
  add_header_above(c(" " = 2, "MAPD" = 3, "SNPQC" = 3, "Waviness SD" = 3), bold = TRUE, align = "c") %&gt;%
  column_spec(2, border_right = TRUE) %&gt;% 
  column_spec(5, border_right = TRUE) %&gt;%
  column_spec(8, border_right = TRUE) %&gt;%
  column_spec(11, border_right = TRUE)

`</span><span class="err">`</span><span class="n">`

We find that all metrics report a Shapiro-Wilk p-value greater than 0.05. Thus, **we accept the null** that our data is approximately normal. This will aid in accepting assumptions necessary to compare our scanner groups - Scanner 1 vs. Scanner 2.

We'll run a Bartlett test for homogeneity of variances to determine whether the variance is roughly equal for the same metric across groups. Our interpretation is that if the Bartlett p-value is **less than 0.05 then we reject the null that the variances in each of the groups are the same**.

`</span><span class="err">`</span><span class="n">`{r bartlett, fig.align='center', echo=FALSE}
variables = c("MAPD", "SNPQC", "Waviness.SD")
bartlett_results = lapply(variables, function(var) {
  test = bartlett.test(s[[var]] ~ s$Scanner)
  data.frame(
    Variable = var,
    Statistic = round(test$statistic, 2),
    p_value = round(test$p.value, 4)
  )
})

bartlett_table = bind_rows(bartlett_results) %&gt;% 
  rownames_to_column() %&gt;%
  select(-rowname)

bartlett_table %&gt;%
  kable(
    digits = 2,
    align = "c",
    col.names = c("Variable", "Bartlett Statistic", "p-value"),
    caption = "Bartlett's Test for Equality of Variances"
  ) %&gt;%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
`</span><span class="err">`</span><span class="n">`

We find that our p-values are greater than 0.05, and **we can accept the null** hypothesis that the variances for each metric are the same across groups. This will allow us to accept assumptions of the statistical test in the next section.

### Two-Sample T-Test for Difference of Groups

We have satisfied the following assumptions for each metric in our data:

-   Data is normally distributed within each group

-   Observations are independent

-   Variance is homogeneous between groups

Thus, the Two-Sample T-Test will be employed to determine whether the the means of the two groups are equal. Our interpretation is that if the Two-Sample T-Test p-value is **less than 0.05 then we reject the null that there is no significant difference between the means of the two groups**.

`</span><span class="err">`</span><span class="n">`{r things, fig.align='center', echo=FALSE}

variables = c("MAPD", "SNPQC", "Waviness.SD")

t_test_results = lapply(variables, function(var) {
  test = t.test(t1[[var]], t2[[var]], alternative = "two.sided", paired = FALSE, var.equal = TRUE)
  data.frame(
    Variable = var,
    T_Statistic = round(test$statistic, 2),
    P_Value = round(test$p.value, 4)
  )
})

t_test_table = bind_rows(t_test_results) %&gt;% 
  rownames_to_column() %&gt;%
  select(-rowname)

t_test_table %&gt;%
  kable(
    digits = 2,
    align = "c",
    col.names = c("Variable", "T Statistic", "P-Value"),
    caption = "Two-Sample T-Test Results"
  ) %&gt;%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))

`</span><span class="err">`</span><span class="n">`

We find that our p-values are greater than 0.05, and **we can accept the null hypothesis that there is no significant difference between the means of the two groups**.

### Conclusion

Based on the metrics `MAPD`, `SNPQC`, and `Waviness</span><span class="w"> </span><span class="n">SD`, **we are confidence that Scanner 1 and Scanner 2 demonstrate comparable performance.**

`</span><span class="err">`</span><span class="n">`{my notes, include=FALSE}
'''
### Discussion of `SNPQC` Distribution

It should be stated first that the Shapiro-Wilks test for normality is a rather powerful test for sample sizes such as ours and that we should be confident in the p-value / our conclusion for normality. Further, we see a distinct agreement in `SNPQC` distribution across both scanners, so the determination of congruence between scanners remains. However, the normality test is reporting a p-value close to 0.05 for both Scanners, and this section will investigate. The distribution for this variable is:

'''
`</span><span class="err">``</span>
</pre></td> </tr></tbody></table></code></pre></figure> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ryan Gallagher. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with the <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme, hosted on <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>